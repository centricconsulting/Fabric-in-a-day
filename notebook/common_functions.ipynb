{"cells":[{"cell_type":"code","source":["def load_csv_to_spark(url: str):\n","    \"\"\"Load CSV data from a URL into a Spark DataFrame.\"\"\"\n","    pdf = pd.read_csv(url)\n","    return spark.createDataFrame(pdf)\n","\n","def table_exists(path: str) -> bool:\n","    \"\"\"Check if a Delta table exists at the given path.\"\"\"\n","    return DeltaTable.isDeltaTable(spark, path)\n","\n","def create_delta_table(df, path: str, table_name: str):\n","    \"\"\"Create a new Delta table from a Spark DataFrame.\"\"\"\n","    df.write.format(\"delta\").mode(\"overwrite\").save(path)\n","    spark.sql(f\"CREATE TABLE IF NOT EXISTS {table_name} USING DELTA LOCATION '{path}'\")\n","    print(f\"Table '{table_name}' created at '{path}'.\")\n","\n","def merge_delta_table(df, path: str, merge_keys: list):\n","    \"\"\"Merge new data into an existing Delta table based on key columns.\"\"\"\n","    delta_table = DeltaTable.forPath(spark, path)\n","\n","    merge_condition = \" AND \".join([f\"tgt.{k} = src.{k}\" for k in merge_keys])\n","\n","    (delta_table.alias(\"tgt\")\n","     .merge(\n","         source=df.alias(\"src\"),\n","         condition=merge_condition\n","     )\n","     .whenMatchedUpdateAll()\n","     .whenNotMatchedInsertAll()\n","     .execute())\n","\n","    print(f\"Data merged into existing Delta table at '{path}'.\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6e4309dd-86d7-4a38-8ce9-5f8fcccd65a6"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{}},"nbformat":4,"nbformat_minor":5}